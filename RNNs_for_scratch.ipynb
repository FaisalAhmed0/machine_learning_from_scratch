{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNNs for scratch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNxlsZeut4OvaaPeopH2zwr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FaisalAhmed0/machine_learning_from_scratch/blob/main/RNNs_for_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7idCn4dhbYN"
      },
      "source": [
        "RNN Using pytorch\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4SWpsnWhVdV"
      },
      "source": [
        "# imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-BiSWig-qnfp",
        "outputId": "3a6abef8-50dd-435c-b5cd-c8963fd40926"
      },
      "source": [
        "# Use GPU is avalible otherwise use cpu.\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cpu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwNrAJdJp12g"
      },
      "source": [
        "# Define the RNN Module\n",
        "class RNN(nn.Module):\n",
        "  '''\n",
        "  This class define a 'vanilla' RNN module\n",
        "  Constructor parameters:\n",
        "    input_dim = dimensionaltiy of the input.\n",
        "    output_dim = dimensionaltiy of the output.\n",
        "  '''\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super().__init__()\n",
        "    # each linear tranformation includes a bias term.\n",
        "    self.linear_hh = nn.Linear(input_dim, output_dim, bias=True) # weights and baises for the hidden state\n",
        "    self.linear_hx = nn.Linear(input_dim, output_dim, bias=True) # weights and baises for the input\n",
        "    self.linear_hy = nn.Linear(input_dim, output_dim, bias=True) # weights and baises for the output\n",
        "\n",
        "  # the forward pass will recive the input x_t and the previous hidden state h_{t-1}\n",
        "  def forward(self, x, h):\n",
        "    h = torch.tanh( self.linear_hh(h) + self.linear_hx(x))\n",
        "    y = self.linear_hy(h)\n",
        "    return y, h"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOEtxMcSslOC"
      },
      "source": [
        "def plot(loss, training_score, validation_score):\n",
        "  '''\n",
        "  helper method to plot the training dynamics.\n",
        "  function parameters:\n",
        "    loss: a list containing the training loss per epoch.\n",
        "    training_score: a list containing the training evaluation score per epoch.\n",
        "    validation_score: a list containing the validation evaluation score per epoch.\n",
        "  '''\n",
        "  iters = range(1, len(loss)+1)\n",
        "  plt.figure()\n",
        "  plt.plot(iters, loss)\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.title(\"Loss curve\")\n",
        "\n",
        "  plt.figure()\n",
        "  plt.plot(iters, training_score, label=\"Training score\")\n",
        "  plt.plot(iters, validation_score, label=\"Validation score\")\n",
        "  plt.legend()\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Score\")\n",
        "\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxM3KIwI8VyX"
      },
      "source": [
        "def onehot(idx, vocab_size):\n",
        "  '''\n",
        "  generate onehot vector given the key in the dictionary and the vocabulary size\n",
        "  '''\n",
        "  onehot_vec = torch.zeros(vocab_size)\n",
        "  onehot_vec[idx] = 1\n",
        "  return onehot_vec"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJCbY_VZ7Uww"
      },
      "source": [
        "# tranform the raw text to input, target pairs\n",
        "def generate_examples(data, char_to_ix, ix_to_char):\n",
        "  '''\n",
        "  data: string that represent the text file\n",
        "  char_to_idx: a dictionary that maps each unique charatcter to a unique index\n",
        "  '''\n",
        "\n",
        "  dataset = []\n",
        "  vocab_size = len(char_to_ix)\n",
        "  for i in range(len(data[:-1])):\n",
        "    idx = char_to_ix[data[i]]\n",
        "    target = char_to_ix[data[i+1]]\n",
        "    dataset.append((onehot(idx, vocab_size), target))\n",
        "  return dataset"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0vAmyFnHECd"
      },
      "source": [
        "def valid_splti(data, split_ratio=0.2):\n",
        "  '''\n",
        "  split the dataset into training and validation sets\n",
        "  '''\n",
        "  data_size = len(data)\n",
        "  split = int (data_size * split_ratio)\n",
        "  train = data[: data_size - split]\n",
        "  valid = data[data_size - split: ]\n",
        "  return train, valid"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jeTIbnQuhLv"
      },
      "source": [
        "# Langauge modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arkiK3iQtmjY"
      },
      "source": [
        "# Training loop to train a langauge model\n",
        "# if score_function is None, compute the accuracy\n",
        "def train(model, criterion, input_seq, y_train ,valid_seq, y_valids ,optimizer, num_epochs):\n",
        "    \"\"\"\n",
        "    This Method runs the optimization loop for learning the parameters, using truncated backpropegation through time\n",
        "    Method parameters:\n",
        "    model: the model object.\n",
        "    criterion: the loss function.\n",
        "    data_loader: training data loader object.\n",
        "    valid_loader: validation data loader object.\n",
        "    optmizer: the optimizer object.\n",
        "    num_epochs: number of training epochs.\n",
        "    The function returns: \n",
        "    losses: a list that containes the loss for every epoch.\n",
        "    training_accuracies: a list that containes the traning accuracy for every epoch.\n",
        "    validation_accuracies: a list that containes the validation accuracy for every epoch.\n",
        "    \"\"\"\n",
        "    # Move model to the device (CPU or GPU).\n",
        "    model = model.to(device)\n",
        "    \n",
        "    # Exponential moving average of the loss.\n",
        "    ema_loss = None\n",
        "\n",
        "    # Losses list \n",
        "    losses = []\n",
        "    # training acuecay list\n",
        "    training_accuracies = []\n",
        "    # valid acuecay list\n",
        "    validation_accuracies = []\n",
        "\n",
        "    # length of the truncated seqeunce\n",
        "    k = 100\n",
        "    #inilize the hidden state to zero\n",
        "    d = input_seq[0].shape\n",
        "\n",
        "    seq_length = len(y_train)\n",
        "    num_iteration = seq_length//k if seq_length % k == 0 else seq_length//k + 1\n",
        "    print('----- Training Loop -----')\n",
        "    # Loop over epochs.\n",
        "    # TODO: put this inside an epoch loop, for now this is only a one epoch\n",
        "    for epoch in range(num_epochs):\n",
        "      correct = 0\n",
        "      k_current = 0\n",
        "      h = torch.zeros(d)\n",
        "      for i in range(num_iteration):\n",
        "        # print(f\"iteration {i}, correct: {correct}\")\n",
        "        loss = 0\n",
        "        # print(loss)\n",
        "        # Make sure model is in training mode.\n",
        "        model.train()   \n",
        "        # Loop over k elemnt in the seqeunce for the forward pass\n",
        "        h = h.detach() # detach the hidden state from the previos timesteps\n",
        "        while (k_current+1)%k != 0 and k_current < len(y_train):\n",
        "          # print(f\"here k is {k_current}\") \n",
        "          x_i = input_seq[k_current]\n",
        "          y_i = y_train[k_current]\n",
        "          output, h = model(torch.unsqueeze(x_i.to(device), dim=0), h.to(device))\n",
        "          # print(output)\n",
        "          # print(h)\n",
        "          # print(y_i)\n",
        "          # Compute the training accuracy\n",
        "          with torch.no_grad():\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            # print(pred)\n",
        "            # print(y_i)\n",
        "            # Count number of correct predictions.\n",
        "            correct += (pred.item() == y_i)\n",
        "            # print(f\"correct: {correct}, pred :{pred}, label: {y_i}, k_current:{k_current}\")\n",
        "\n",
        "          loss += criterion(output,  torch.tensor([y_i], device=device))\n",
        "          k_current += 1\n",
        "\n",
        "        k_current += 1\n",
        "        if k_current < len(y_train):\n",
        "          # print(f\"here k is {k_current}\")\n",
        "          x_i = input_seq[k_current]\n",
        "          y_i = y_train[k_current]\n",
        "          output, h = model(torch.unsqueeze(x_i.to(device), dim=0), h.to(device))\n",
        "          # print(output)\n",
        "          # print(h)\n",
        "          # print(y_i)\n",
        "          # Compute the training accuracy\n",
        "          with torch.no_grad():\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            # print(pred)\n",
        "            # print(y_i)\n",
        "            # Count number of correct predictions.\n",
        "            correct += (pred.item() == y_i)\n",
        "            # print(f\"correct: {correct}, pred :{pred}, label: {y_i}, k_current:{k_current}\")\n",
        "\n",
        "          loss += criterion(output,  torch.tensor([y_i], device=device))\n",
        "        \n",
        "        # Backward pass\n",
        "        if loss != 0:\n",
        "          optimizer.zero_grad()\n",
        "          loss /= k\n",
        "          # print(f\" k is {k_current}\")\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "        \n",
        "      # NOTE: It is important to call .item() on the loss before summing.\n",
        "      if ema_loss is None:\n",
        "          ema_loss = loss.item()\n",
        "      else:\n",
        "          ema_loss += (loss - ema_loss) * 0.01\n",
        "      \n",
        "      train_score = 100. * correct / seq_length # training score\n",
        "\n",
        "      # Compute the validation accuracy\n",
        "      model.eval()  # switch to evaliation mode\n",
        "      h = torch.zeros(d)\n",
        "      correct = 0\n",
        "      valid_seq_len = len(y_valids)\n",
        "      with torch.no_grad():\n",
        "        for x_valid, y_valid in zip(valid_seq, y_valids):\n",
        "          output, h = model(x_valid.to(device), h.to(device))\n",
        "          pred = output.argmax(dim=0)\n",
        "          # Count number of correct predictions.\n",
        "          correct += (pred.cpu().item() == y_valid)\n",
        "      valid_score = 100. * correct / valid_seq_len # validation score\n",
        "      \n",
        "      losses.append(ema_loss)\n",
        "      training_accuracies.append(train_score)\n",
        "      validation_accuracies.append(valid_score)\n",
        "      # print(ema_loss)\n",
        "      print('Epoch: {} \\tLoss: {:.12f} \\tTraining Accuracy: {:.12f} \\t Validation Accuracy: {:.12f}'.format(epoch, ema_loss, train_score, valid_score),)\n",
        "\n",
        "    return losses, training_accuracies, validation_accuracies"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oormiZNe5PNe"
      },
      "source": [
        "# Load the data\n",
        "# These lines are copied from https://gist.github.com/karpathy/d4dee566867f8291f086\n",
        "# data I/O\n",
        "def getData(filepath):\n",
        "  '''\n",
        "  given the file-path the will return the raw text as a string in the variable 'data', and two dictionaries:\n",
        "  char_to_ix: maps a unique character to a unique index.\n",
        "  ix_to_char: maps the index back to its character.\n",
        "  '''\n",
        "  data = open(filepath, 'r').read() # should be simple plain text file\n",
        "  chars = list(set(data))\n",
        "  data_size, vocab_size = len(data), len(chars)\n",
        "  print ('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
        "  char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
        "  ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
        "  return data, char_to_ix, ix_to_char"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LfkfWLUE4VS",
        "outputId": "b5458290-3039-4cf8-e2e7-cfa9539fc474"
      },
      "source": [
        "# Tranform the row text to a training dataset\n",
        "filepath = \"input.txt\"\n",
        "data, char_to_ix, ix_to_char = getData(filepath)\n",
        "dataset = generate_examples(data, char_to_ix, ix_to_char)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data has 79835 characters, 73 unique.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EpoTh2QG0ET"
      },
      "source": [
        "# split into training and validation \n",
        "train_set, validation_set = valid_splti(dataset, 0.001)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdVR9-5XKQk1"
      },
      "source": [
        "# split the inputs and the outputs\n",
        "x_train, y_train, x_valid, y_valid = [], [], [], []\n",
        "for x, y in train_set:\n",
        "  x_train.append(x)\n",
        "  y_train.append(y)\n",
        "for x, y in validation_set:\n",
        "  x_valid.append(x)\n",
        "  y_valid.append(y)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztK7IylsH1pH"
      },
      "source": [
        "# Define the model\n",
        "lr = 1e-3 # learning rate\n",
        "epochs = 500 # number of epochs\n",
        "rnn = RNN(73, 73) \n",
        "criterion = torch.nn.CrossEntropyLoss() # loss function\n",
        "optimizer = optim.Adam(rnn.parameters(), lr=lr) # optimizer"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ar-ME9EvIjF0",
        "outputId": "0cdf857d-85b6-4907-873d-74b718510823"
      },
      "source": [
        "# fit the model\n",
        "loss, train_socre, valid_score = train(rnn, criterion, x_train, y_train, x_valid, y_valid, optimizer, epochs)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----- Training Loop -----\n",
            "Epoch: 0 \tLoss: 1.405218243599 \tTraining Accuracy: 26.190207510501 \t Validation Accuracy: 35.443037974684\n",
            "Epoch: 1 \tLoss: 1.404169201851 \tTraining Accuracy: 36.538148078490 \t Validation Accuracy: 32.911392405063\n",
            "Epoch: 2 \tLoss: 1.402511954308 \tTraining Accuracy: 41.290201241301 \t Validation Accuracy: 37.974683544304\n",
            "Epoch: 3 \tLoss: 1.400360941887 \tTraining Accuracy: 45.045451695818 \t Validation Accuracy: 43.037974683544\n",
            "Epoch: 4 \tLoss: 1.397731065750 \tTraining Accuracy: 47.553131465112 \t Validation Accuracy: 43.037974683544\n",
            "Epoch: 5 \tLoss: 1.394677996635 \tTraining Accuracy: 49.497837126199 \t Validation Accuracy: 44.303797468354\n",
            "Epoch: 6 \tLoss: 1.391263604164 \tTraining Accuracy: 50.959814431697 \t Validation Accuracy: 46.835443037975\n",
            "Epoch: 7 \tLoss: 1.387531757355 \tTraining Accuracy: 52.425553256849 \t Validation Accuracy: 45.569620253165\n",
            "Epoch: 8 \tLoss: 1.383507728577 \tTraining Accuracy: 53.738323616074 \t Validation Accuracy: 49.367088607595\n",
            "Epoch: 9 \tLoss: 1.379198312759 \tTraining Accuracy: 54.913171587988 \t Validation Accuracy: 50.632911392405\n",
            "Epoch: 10 \tLoss: 1.374609708786 \tTraining Accuracy: 55.813428625165 \t Validation Accuracy: 51.898734177215\n",
            "Epoch: 11 \tLoss: 1.369757413864 \tTraining Accuracy: 56.539401918375 \t Validation Accuracy: 54.430379746835\n",
            "Epoch: 12 \tLoss: 1.364668369293 \tTraining Accuracy: 57.143752742775 \t Validation Accuracy: 55.696202531646\n",
            "Epoch: 13 \tLoss: 1.359368801117 \tTraining Accuracy: 57.812049401291 \t Validation Accuracy: 55.696202531646\n",
            "Epoch: 14 \tLoss: 1.353885531425 \tTraining Accuracy: 58.316093034919 \t Validation Accuracy: 55.696202531646\n",
            "Epoch: 15 \tLoss: 1.348251819611 \tTraining Accuracy: 58.803836750047 \t Validation Accuracy: 54.430379746835\n",
            "Epoch: 16 \tLoss: 1.342506647110 \tTraining Accuracy: 59.266503667482 \t Validation Accuracy: 53.164556962025\n",
            "Epoch: 17 \tLoss: 1.336677312851 \tTraining Accuracy: 59.611309635760 \t Validation Accuracy: 54.430379746835\n",
            "Epoch: 18 \tLoss: 1.330784797668 \tTraining Accuracy: 59.984953921384 \t Validation Accuracy: 54.430379746835\n",
            "Epoch: 19 \tLoss: 1.324853181839 \tTraining Accuracy: 60.475205316281 \t Validation Accuracy: 54.430379746835\n",
            "Epoch: 20 \tLoss: 1.318885803223 \tTraining Accuracy: 60.911541596138 \t Validation Accuracy: 53.164556962025\n",
            "Epoch: 21 \tLoss: 1.312912106514 \tTraining Accuracy: 61.365431634380 \t Validation Accuracy: 55.696202531646\n",
            "Epoch: 22 \tLoss: 1.306924343109 \tTraining Accuracy: 61.670114726349 \t Validation Accuracy: 54.430379746835\n",
            "Epoch: 23 \tLoss: 1.300945997238 \tTraining Accuracy: 61.973543978434 \t Validation Accuracy: 56.962025316456\n",
            "Epoch: 24 \tLoss: 1.294976234436 \tTraining Accuracy: 62.162873801016 \t Validation Accuracy: 55.696202531646\n",
            "Epoch: 25 \tLoss: 1.289006948471 \tTraining Accuracy: 62.355965143251 \t Validation Accuracy: 56.962025316456\n",
            "Epoch: 26 \tLoss: 1.283030748367 \tTraining Accuracy: 62.471318412639 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 27 \tLoss: 1.277096390724 \tTraining Accuracy: 62.753432386684 \t Validation Accuracy: 56.962025316456\n",
            "Epoch: 28 \tLoss: 1.271233797073 \tTraining Accuracy: 62.890100934111 \t Validation Accuracy: 56.962025316456\n",
            "Epoch: 29 \tLoss: 1.265411257744 \tTraining Accuracy: 63.133345871732 \t Validation Accuracy: 55.696202531646\n",
            "Epoch: 30 \tLoss: 1.259577631950 \tTraining Accuracy: 63.147138110463 \t Validation Accuracy: 53.164556962025\n",
            "Epoch: 31 \tLoss: 1.253748297691 \tTraining Accuracy: 63.188514826657 \t Validation Accuracy: 53.164556962025\n",
            "Epoch: 32 \tLoss: 1.247897028923 \tTraining Accuracy: 63.317660334775 \t Validation Accuracy: 53.164556962025\n",
            "Epoch: 33 \tLoss: 1.242141127586 \tTraining Accuracy: 63.305121935929 \t Validation Accuracy: 54.430379746835\n",
            "Epoch: 34 \tLoss: 1.236267089844 \tTraining Accuracy: 63.456836561971 \t Validation Accuracy: 54.430379746835\n",
            "Epoch: 35 \tLoss: 1.230449199677 \tTraining Accuracy: 63.564666792051 \t Validation Accuracy: 53.164556962025\n",
            "Epoch: 36 \tLoss: 1.224754691124 \tTraining Accuracy: 63.558397592627 \t Validation Accuracy: 53.164556962025\n",
            "Epoch: 37 \tLoss: 1.219130635262 \tTraining Accuracy: 63.681273901323 \t Validation Accuracy: 50.632911392405\n",
            "Epoch: 38 \tLoss: 1.213618993759 \tTraining Accuracy: 63.705096859131 \t Validation Accuracy: 53.164556962025\n",
            "Epoch: 39 \tLoss: 1.208419680595 \tTraining Accuracy: 63.913234279982 \t Validation Accuracy: 54.430379746835\n",
            "Epoch: 40 \tLoss: 1.203120589256 \tTraining Accuracy: 63.909472760329 \t Validation Accuracy: 53.164556962025\n",
            "Epoch: 41 \tLoss: 1.198087096214 \tTraining Accuracy: 63.968403234907 \t Validation Accuracy: 50.632911392405\n",
            "Epoch: 42 \tLoss: 1.193052768707 \tTraining Accuracy: 64.046141307755 \t Validation Accuracy: 51.898734177215\n",
            "Epoch: 43 \tLoss: 1.188026070595 \tTraining Accuracy: 64.227948091029 \t Validation Accuracy: 56.962025316456\n",
            "Epoch: 44 \tLoss: 1.183012843132 \tTraining Accuracy: 64.202871293336 \t Validation Accuracy: 54.430379746835\n",
            "Epoch: 45 \tLoss: 1.178017258644 \tTraining Accuracy: 64.189079054605 \t Validation Accuracy: 51.898734177215\n",
            "Epoch: 46 \tLoss: 1.173002004623 \tTraining Accuracy: 64.352078239609 \t Validation Accuracy: 50.632911392405\n",
            "Epoch: 47 \tLoss: 1.167716026306 \tTraining Accuracy: 64.531377343113 \t Validation Accuracy: 54.430379746835\n",
            "Epoch: 48 \tLoss: 1.162783622742 \tTraining Accuracy: 64.645476772616 \t Validation Accuracy: 55.696202531646\n",
            "Epoch: 49 \tLoss: 1.157798409462 \tTraining Accuracy: 64.596577017115 \t Validation Accuracy: 55.696202531646\n",
            "Epoch: 50 \tLoss: 1.152528285980 \tTraining Accuracy: 64.552692621152 \t Validation Accuracy: 54.430379746835\n",
            "Epoch: 51 \tLoss: 1.147801637650 \tTraining Accuracy: 64.759576202119 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 52 \tLoss: 1.142808914185 \tTraining Accuracy: 64.910036988277 \t Validation Accuracy: 55.696202531646\n",
            "Epoch: 53 \tLoss: 1.138264179230 \tTraining Accuracy: 64.872421791737 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 54 \tLoss: 1.133486509323 \tTraining Accuracy: 64.953921384239 \t Validation Accuracy: 55.696202531646\n",
            "Epoch: 55 \tLoss: 1.128836631775 \tTraining Accuracy: 64.980252021817 \t Validation Accuracy: 55.696202531646\n",
            "Epoch: 56 \tLoss: 1.124261617661 \tTraining Accuracy: 64.946398344931 \t Validation Accuracy: 56.962025316456\n",
            "Epoch: 57 \tLoss: 1.119798898697 \tTraining Accuracy: 65.190897122437 \t Validation Accuracy: 53.164556962025\n",
            "Epoch: 58 \tLoss: 1.115561366081 \tTraining Accuracy: 65.183374083130 \t Validation Accuracy: 56.962025316456\n",
            "Epoch: 59 \tLoss: 1.111028909683 \tTraining Accuracy: 65.287442793555 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 60 \tLoss: 1.106512188911 \tTraining Accuracy: 65.348880947903 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 61 \tLoss: 1.101997017860 \tTraining Accuracy: 65.291204313209 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 62 \tLoss: 1.097810745239 \tTraining Accuracy: 65.299981192402 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 63 \tLoss: 1.094016432762 \tTraining Accuracy: 65.327565669864 \t Validation Accuracy: 56.962025316456\n",
            "Epoch: 64 \tLoss: 1.089923620224 \tTraining Accuracy: 65.382734624788 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 65 \tLoss: 1.085834980011 \tTraining Accuracy: 65.450441978559 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 66 \tLoss: 1.081659197807 \tTraining Accuracy: 65.540718450254 \t Validation Accuracy: 56.962025316456\n",
            "Epoch: 67 \tLoss: 1.077305316925 \tTraining Accuracy: 65.546987649677 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 68 \tLoss: 1.073280692101 \tTraining Accuracy: 65.588364365870 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 69 \tLoss: 1.068997383118 \tTraining Accuracy: 65.464234217290 \t Validation Accuracy: 56.962025316456\n",
            "Epoch: 70 \tLoss: 1.064595103264 \tTraining Accuracy: 65.692433076296 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 71 \tLoss: 1.060696482658 \tTraining Accuracy: 65.587110525986 \t Validation Accuracy: 56.962025316456\n",
            "Epoch: 72 \tLoss: 1.056814312935 \tTraining Accuracy: 65.709986834681 \t Validation Accuracy: 56.962025316456\n",
            "Epoch: 73 \tLoss: 1.052734971046 \tTraining Accuracy: 65.642279480910 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 74 \tLoss: 1.048372387886 \tTraining Accuracy: 65.804024826030 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 75 \tLoss: 1.044484853745 \tTraining Accuracy: 65.809040185568 \t Validation Accuracy: 56.962025316456\n",
            "Epoch: 76 \tLoss: 1.040153384209 \tTraining Accuracy: 65.934424174033 \t Validation Accuracy: 55.696202531646\n",
            "Epoch: 77 \tLoss: 1.035995483398 \tTraining Accuracy: 65.792740267068 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 78 \tLoss: 1.031963586807 \tTraining Accuracy: 65.929408814494 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 79 \tLoss: 1.028201818466 \tTraining Accuracy: 65.920631935302 \t Validation Accuracy: 55.696202531646\n",
            "Epoch: 80 \tLoss: 1.024189591408 \tTraining Accuracy: 65.884270578647 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 81 \tLoss: 1.020502209663 \tTraining Accuracy: 66.059808162498 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 82 \tLoss: 1.016759634018 \tTraining Accuracy: 65.955739452072 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 83 \tLoss: 1.013120770454 \tTraining Accuracy: 65.945708732995 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 84 \tLoss: 1.009398579597 \tTraining Accuracy: 66.042254404113 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 85 \tLoss: 1.005905747414 \tTraining Accuracy: 66.198984389693 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 86 \tLoss: 1.002474546432 \tTraining Accuracy: 66.150084634192 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 87 \tLoss: 0.999002873898 \tTraining Accuracy: 66.209015108771 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 88 \tLoss: 0.995607972145 \tTraining Accuracy: 66.131277035923 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 89 \tLoss: 0.991973102093 \tTraining Accuracy: 66.182684471193 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 90 \tLoss: 0.988445043564 \tTraining Accuracy: 66.423421729045 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 91 \tLoss: 0.984970986843 \tTraining Accuracy: 66.150084634192 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 92 \tLoss: 0.981851279736 \tTraining Accuracy: 66.064823522036 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 93 \tLoss: 0.978853046894 \tTraining Accuracy: 66.264184063695 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 94 \tLoss: 0.975620269775 \tTraining Accuracy: 66.271707103003 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 95 \tLoss: 0.972417473793 \tTraining Accuracy: 66.403360290891 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 96 \tLoss: 0.969185888767 \tTraining Accuracy: 66.286753181619 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 97 \tLoss: 0.965979099274 \tTraining Accuracy: 66.325622218043 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 98 \tLoss: 0.962757229805 \tTraining Accuracy: 66.432198608238 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 99 \tLoss: 0.959543764591 \tTraining Accuracy: 66.126261676384 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 100 \tLoss: 0.956516921520 \tTraining Accuracy: 66.482352203624 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 101 \tLoss: 0.953565478325 \tTraining Accuracy: 66.271707103003 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 102 \tLoss: 0.950507581234 \tTraining Accuracy: 66.382045012852 \t Validation Accuracy: 54.430379746835\n",
            "Epoch: 103 \tLoss: 0.947967708111 \tTraining Accuracy: 66.494890602470 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 104 \tLoss: 0.945286393166 \tTraining Accuracy: 66.527490439471 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 105 \tLoss: 0.942529082298 \tTraining Accuracy: 66.471067644662 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 106 \tLoss: 0.939965307713 \tTraining Accuracy: 66.486113723278 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 107 \tLoss: 0.937358677387 \tTraining Accuracy: 66.402106451006 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 108 \tLoss: 0.934445679188 \tTraining Accuracy: 66.502413641778 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 109 \tLoss: 0.931743264198 \tTraining Accuracy: 66.596451633126 \t Validation Accuracy: 56.962025316456\n",
            "Epoch: 110 \tLoss: 0.929068148136 \tTraining Accuracy: 66.675443545859 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 111 \tLoss: 0.926410675049 \tTraining Accuracy: 66.529998119240 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 112 \tLoss: 0.923644602299 \tTraining Accuracy: 66.508682841201 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 113 \tLoss: 0.920903980732 \tTraining Accuracy: 66.482352203624 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 114 \tLoss: 0.918103277683 \tTraining Accuracy: 66.790796815247 \t Validation Accuracy: 67.088607594937\n",
            "Epoch: 115 \tLoss: 0.915444374084 \tTraining Accuracy: 66.487367563162 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 116 \tLoss: 0.913106739521 \tTraining Accuracy: 66.695504984014 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 117 \tLoss: 0.910725414753 \tTraining Accuracy: 66.670428186321 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 118 \tLoss: 0.908341765404 \tTraining Accuracy: 66.473575324431 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 119 \tLoss: 0.905964314938 \tTraining Accuracy: 66.614005391511 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 120 \tLoss: 0.904090881348 \tTraining Accuracy: 66.660397467243 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 121 \tLoss: 0.901641786098 \tTraining Accuracy: 66.499905962009 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 122 \tLoss: 0.899205923080 \tTraining Accuracy: 66.610243871858 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 123 \tLoss: 0.897341549397 \tTraining Accuracy: 66.457275405931 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 124 \tLoss: 0.894906461239 \tTraining Accuracy: 66.654128267820 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 125 \tLoss: 0.893322467804 \tTraining Accuracy: 66.743150899630 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 126 \tLoss: 0.891074240208 \tTraining Accuracy: 66.591436273588 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 127 \tLoss: 0.888550519943 \tTraining Accuracy: 66.681712745282 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 128 \tLoss: 0.886506676674 \tTraining Accuracy: 66.721835621591 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 129 \tLoss: 0.884393036366 \tTraining Accuracy: 66.600213152780 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 130 \tLoss: 0.882309079170 \tTraining Accuracy: 66.670428186321 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 131 \tLoss: 0.880493581295 \tTraining Accuracy: 66.878565607172 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 132 \tLoss: 0.878378331661 \tTraining Accuracy: 66.433452448122 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 133 \tLoss: 0.876488685608 \tTraining Accuracy: 66.864773368441 \t Validation Accuracy: 56.962025316456\n",
            "Epoch: 134 \tLoss: 0.874018609524 \tTraining Accuracy: 66.706789542975 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 135 \tLoss: 0.872265577316 \tTraining Accuracy: 66.646605228512 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 136 \tLoss: 0.870556771755 \tTraining Accuracy: 66.824650492132 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 137 \tLoss: 0.868848860264 \tTraining Accuracy: 66.649112908282 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 138 \tLoss: 0.866585731506 \tTraining Accuracy: 66.996426556329 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 139 \tLoss: 0.864715754986 \tTraining Accuracy: 66.745658579399 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 140 \tLoss: 0.862936973572 \tTraining Accuracy: 66.766973857438 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 141 \tLoss: 0.860602140427 \tTraining Accuracy: 66.785781455708 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 142 \tLoss: 0.858306705952 \tTraining Accuracy: 66.705535703091 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 143 \tLoss: 0.855734467506 \tTraining Accuracy: 66.755689298477 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 144 \tLoss: 0.854043424129 \tTraining Accuracy: 66.662905147013 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 145 \tLoss: 0.851951956749 \tTraining Accuracy: 67.087956867908 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 146 \tLoss: 0.849679768085 \tTraining Accuracy: 67.036549432637 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 147 \tLoss: 0.848113536835 \tTraining Accuracy: 66.852234969594 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 148 \tLoss: 0.846676468849 \tTraining Accuracy: 66.774496896746 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 149 \tLoss: 0.844517290592 \tTraining Accuracy: 67.007711115291 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 150 \tLoss: 0.842428267002 \tTraining Accuracy: 67.070403109523 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 151 \tLoss: 0.840464115143 \tTraining Accuracy: 67.006457275406 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 152 \tLoss: 0.838716685772 \tTraining Accuracy: 67.169456460410 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 153 \tLoss: 0.837039768696 \tTraining Accuracy: 67.260986771989 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 154 \tLoss: 0.835477888584 \tTraining Accuracy: 66.764466177669 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 155 \tLoss: 0.833850920200 \tTraining Accuracy: 67.234656134412 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 156 \tLoss: 0.832280099392 \tTraining Accuracy: 67.087956867908 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 157 \tLoss: 0.830148398876 \tTraining Accuracy: 67.082941508369 \t Validation Accuracy: 56.962025316456\n",
            "Epoch: 158 \tLoss: 0.828250229359 \tTraining Accuracy: 67.116795185255 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 159 \tLoss: 0.827060580254 \tTraining Accuracy: 66.760704658015 \t Validation Accuracy: 65.822784810127\n",
            "Epoch: 160 \tLoss: 0.825359404087 \tTraining Accuracy: 67.125572064447 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 161 \tLoss: 0.823156774044 \tTraining Accuracy: 67.214594696257 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 162 \tLoss: 0.821364939213 \tTraining Accuracy: 66.938749921635 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 163 \tLoss: 0.819502890110 \tTraining Accuracy: 67.060372390446 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 164 \tLoss: 0.818194448948 \tTraining Accuracy: 67.120556704909 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 165 \tLoss: 0.816274046898 \tTraining Accuracy: 66.872296407749 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 166 \tLoss: 0.814612984657 \tTraining Accuracy: 67.184502539026 \t Validation Accuracy: 65.822784810127\n",
            "Epoch: 167 \tLoss: 0.813151121140 \tTraining Accuracy: 67.176979499718 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 168 \tLoss: 0.811841905117 \tTraining Accuracy: 67.293586608990 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 169 \tLoss: 0.810573875904 \tTraining Accuracy: 66.852234969594 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 170 \tLoss: 0.809254884720 \tTraining Accuracy: 67.292332769105 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 171 \tLoss: 0.807685852051 \tTraining Accuracy: 67.091718387562 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 172 \tLoss: 0.806344330311 \tTraining Accuracy: 67.396401479531 \t Validation Accuracy: 67.088607594937\n",
            "Epoch: 173 \tLoss: 0.804778337479 \tTraining Accuracy: 66.922450003135 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 174 \tLoss: 0.803871870041 \tTraining Accuracy: 67.421478277224 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 175 \tLoss: 0.802478015423 \tTraining Accuracy: 67.390132280108 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 176 \tLoss: 0.801552176476 \tTraining Accuracy: 67.283555889913 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 177 \tLoss: 0.799926757812 \tTraining Accuracy: 67.131841263871 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 178 \tLoss: 0.798326551914 \tTraining Accuracy: 67.245940693373 \t Validation Accuracy: 65.822784810127\n",
            "Epoch: 179 \tLoss: 0.796823978424 \tTraining Accuracy: 67.194533258103 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 180 \tLoss: 0.795658409595 \tTraining Accuracy: 67.268509811297 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 181 \tLoss: 0.794731497765 \tTraining Accuracy: 67.579462102689 \t Validation Accuracy: 65.822784810127\n",
            "Epoch: 182 \tLoss: 0.793146789074 \tTraining Accuracy: 67.339978684722 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 183 \tLoss: 0.792238473892 \tTraining Accuracy: 67.199548617642 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 184 \tLoss: 0.791298806667 \tTraining Accuracy: 67.293586608990 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 185 \tLoss: 0.789998769760 \tTraining Accuracy: 67.301109648298 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 186 \tLoss: 0.788807511330 \tTraining Accuracy: 66.998934236098 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 187 \tLoss: 0.787806987762 \tTraining Accuracy: 67.253463732681 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 188 \tLoss: 0.786468923092 \tTraining Accuracy: 67.355024763338 \t Validation Accuracy: 67.088607594937\n",
            "Epoch: 189 \tLoss: 0.785187244415 \tTraining Accuracy: 67.385116920569 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 190 \tLoss: 0.784685969353 \tTraining Accuracy: 67.054103191023 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 191 \tLoss: 0.783502280712 \tTraining Accuracy: 67.377593881261 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 192 \tLoss: 0.782369613647 \tTraining Accuracy: 67.475393392264 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 193 \tLoss: 0.781113684177 \tTraining Accuracy: 67.490439470880 \t Validation Accuracy: 56.962025316456\n",
            "Epoch: 194 \tLoss: 0.780583739281 \tTraining Accuracy: 67.200802457526 \t Validation Accuracy: 55.696202531646\n",
            "Epoch: 195 \tLoss: 0.779959440231 \tTraining Accuracy: 67.350009403799 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 196 \tLoss: 0.778648614883 \tTraining Accuracy: 67.278540530374 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 197 \tLoss: 0.777440249920 \tTraining Accuracy: 66.893611685788 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 198 \tLoss: 0.776306450367 \tTraining Accuracy: 67.402670678954 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 199 \tLoss: 0.775738239288 \tTraining Accuracy: 67.308632687606 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 200 \tLoss: 0.774113237858 \tTraining Accuracy: 67.365055482415 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 201 \tLoss: 0.773197174072 \tTraining Accuracy: 67.382609240800 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 202 \tLoss: 0.772067487240 \tTraining Accuracy: 67.474139552379 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 203 \tLoss: 0.771321594715 \tTraining Accuracy: 67.213340856373 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 204 \tLoss: 0.770495593548 \tTraining Accuracy: 67.510500909034 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 205 \tLoss: 0.769959926605 \tTraining Accuracy: 67.505485549495 \t Validation Accuracy: 65.822784810127\n",
            "Epoch: 206 \tLoss: 0.769070863724 \tTraining Accuracy: 67.407686038493 \t Validation Accuracy: 65.822784810127\n",
            "Epoch: 207 \tLoss: 0.767808377743 \tTraining Accuracy: 67.321171086452 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 208 \tLoss: 0.766673266888 \tTraining Accuracy: 67.328694125760 \t Validation Accuracy: 65.822784810127\n",
            "Epoch: 209 \tLoss: 0.765969157219 \tTraining Accuracy: 67.337471004953 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 210 \tLoss: 0.765187323093 \tTraining Accuracy: 67.417716757570 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 211 \tLoss: 0.764424979687 \tTraining Accuracy: 67.334963325183 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 212 \tLoss: 0.763576030731 \tTraining Accuracy: 67.327440285875 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 213 \tLoss: 0.762575149536 \tTraining Accuracy: 67.544354585919 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 214 \tLoss: 0.762740790844 \tTraining Accuracy: 67.386370760454 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 215 \tLoss: 0.762022495270 \tTraining Accuracy: 67.388878440223 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 216 \tLoss: 0.761126995087 \tTraining Accuracy: 67.726161369193 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 217 \tLoss: 0.759665191174 \tTraining Accuracy: 67.460347313648 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 218 \tLoss: 0.758961677551 \tTraining Accuracy: 66.958811359789 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 219 \tLoss: 0.758193552494 \tTraining Accuracy: 67.573192903266 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 220 \tLoss: 0.757098793983 \tTraining Accuracy: 67.649677136230 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 221 \tLoss: 0.756167471409 \tTraining Accuracy: 67.556892984766 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 222 \tLoss: 0.755493283272 \tTraining Accuracy: 67.184502539026 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 223 \tLoss: 0.754452645779 \tTraining Accuracy: 67.397655319416 \t Validation Accuracy: 56.962025316456\n",
            "Epoch: 224 \tLoss: 0.753321170807 \tTraining Accuracy: 67.459093473763 \t Validation Accuracy: 69.620253164557\n",
            "Epoch: 225 \tLoss: 0.752466559410 \tTraining Accuracy: 67.480408751802 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 226 \tLoss: 0.751798689365 \tTraining Accuracy: 67.753745846655 \t Validation Accuracy: 65.822784810127\n",
            "Epoch: 227 \tLoss: 0.751055896282 \tTraining Accuracy: 67.430255156417 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 228 \tLoss: 0.750121951103 \tTraining Accuracy: 67.447808914802 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 229 \tLoss: 0.749598860741 \tTraining Accuracy: 67.507993229265 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 230 \tLoss: 0.748836994171 \tTraining Accuracy: 67.183248699141 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 231 \tLoss: 0.747804045677 \tTraining Accuracy: 67.452824274340 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 232 \tLoss: 0.747094213963 \tTraining Accuracy: 67.623346498652 \t Validation Accuracy: 65.822784810127\n",
            "Epoch: 233 \tLoss: 0.746269524097 \tTraining Accuracy: 67.318663406683 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 234 \tLoss: 0.745671033859 \tTraining Accuracy: 67.338724844837 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 235 \tLoss: 0.744552731514 \tTraining Accuracy: 67.351263243684 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 236 \tLoss: 0.743463456631 \tTraining Accuracy: 67.500470189957 \t Validation Accuracy: 65.822784810127\n",
            "Epoch: 237 \tLoss: 0.742425620556 \tTraining Accuracy: 67.401416839070 \t Validation Accuracy: 67.088607594937\n",
            "Epoch: 238 \tLoss: 0.741371631622 \tTraining Accuracy: 67.327440285875 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 239 \tLoss: 0.740593731403 \tTraining Accuracy: 67.752492006771 \t Validation Accuracy: 65.822784810127\n",
            "Epoch: 240 \tLoss: 0.739866197109 \tTraining Accuracy: 67.412701398031 \t Validation Accuracy: 65.822784810127\n",
            "Epoch: 241 \tLoss: 0.738784015179 \tTraining Accuracy: 67.459093473763 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 242 \tLoss: 0.737669765949 \tTraining Accuracy: 67.332455645414 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 243 \tLoss: 0.736825048923 \tTraining Accuracy: 67.787599523541 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 244 \tLoss: 0.736227333546 \tTraining Accuracy: 67.724907529309 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 245 \tLoss: 0.735519587994 \tTraining Accuracy: 67.484170271456 \t Validation Accuracy: 65.822784810127\n",
            "Epoch: 246 \tLoss: 0.734692692757 \tTraining Accuracy: 67.427747476647 \t Validation Accuracy: 67.088607594937\n",
            "Epoch: 247 \tLoss: 0.733848869801 \tTraining Accuracy: 67.733684408501 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 248 \tLoss: 0.733050763607 \tTraining Accuracy: 67.765030405617 \t Validation Accuracy: 56.962025316456\n",
            "Epoch: 249 \tLoss: 0.732490181923 \tTraining Accuracy: 67.219610055796 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 250 \tLoss: 0.731746673584 \tTraining Accuracy: 67.441539715378 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 251 \tLoss: 0.731512784958 \tTraining Accuracy: 67.633377217729 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 252 \tLoss: 0.730785548687 \tTraining Accuracy: 67.751238166886 \t Validation Accuracy: 56.962025316456\n",
            "Epoch: 253 \tLoss: 0.729568123817 \tTraining Accuracy: 67.697323051846 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 254 \tLoss: 0.728644371033 \tTraining Accuracy: 67.564416024074 \t Validation Accuracy: 65.822784810127\n",
            "Epoch: 255 \tLoss: 0.727806627750 \tTraining Accuracy: 67.565669863958 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 256 \tLoss: 0.727257549763 \tTraining Accuracy: 67.634631057614 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 257 \tLoss: 0.726779699326 \tTraining Accuracy: 67.846529998119 \t Validation Accuracy: 65.822784810127\n",
            "Epoch: 258 \tLoss: 0.725812613964 \tTraining Accuracy: 67.496708670303 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 259 \tLoss: 0.725204288960 \tTraining Accuracy: 67.881637514889 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 260 \tLoss: 0.724629998207 \tTraining Accuracy: 67.457839633879 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 261 \tLoss: 0.723669826984 \tTraining Accuracy: 67.694815372077 \t Validation Accuracy: 67.088607594937\n",
            "Epoch: 262 \tLoss: 0.722980678082 \tTraining Accuracy: 68.062190458278 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 263 \tLoss: 0.722539305687 \tTraining Accuracy: 67.529308507304 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 264 \tLoss: 0.722108662128 \tTraining Accuracy: 67.817691680772 \t Validation Accuracy: 67.088607594937\n",
            "Epoch: 265 \tLoss: 0.721118509769 \tTraining Accuracy: 67.533070026958 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 266 \tLoss: 0.720075428486 \tTraining Accuracy: 67.403924518839 \t Validation Accuracy: 65.822784810127\n",
            "Epoch: 267 \tLoss: 0.719121992588 \tTraining Accuracy: 67.658454015422 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 268 \tLoss: 0.718319296837 \tTraining Accuracy: 67.667230894615 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 269 \tLoss: 0.718006134033 \tTraining Accuracy: 67.627108018306 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 270 \tLoss: 0.717469215393 \tTraining Accuracy: 67.550623785343 \t Validation Accuracy: 68.354430379747\n",
            "Epoch: 271 \tLoss: 0.716952562332 \tTraining Accuracy: 67.658454015422 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 272 \tLoss: 0.715996444225 \tTraining Accuracy: 67.472885712495 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 273 \tLoss: 0.715361356735 \tTraining Accuracy: 67.452824274340 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 274 \tLoss: 0.714795231819 \tTraining Accuracy: 67.766284245502 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 275 \tLoss: 0.714147984982 \tTraining Accuracy: 67.854053037427 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 276 \tLoss: 0.713450849056 \tTraining Accuracy: 67.263494451759 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 277 \tLoss: 0.712520420551 \tTraining Accuracy: 67.716130650116 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 278 \tLoss: 0.711627066135 \tTraining Accuracy: 67.931791110275 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 279 \tLoss: 0.710889399052 \tTraining Accuracy: 67.612061939690 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 280 \tLoss: 0.710100352764 \tTraining Accuracy: 67.260986771989 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 281 \tLoss: 0.709113836288 \tTraining Accuracy: 67.894175913736 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 282 \tLoss: 0.708381533623 \tTraining Accuracy: 67.806407121811 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 283 \tLoss: 0.707504749298 \tTraining Accuracy: 67.103002946524 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 284 \tLoss: 0.706752300262 \tTraining Accuracy: 67.766284245502 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 285 \tLoss: 0.705904006958 \tTraining Accuracy: 67.844022318350 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 286 \tLoss: 0.704936981201 \tTraining Accuracy: 67.904206632813 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 287 \tLoss: 0.704206883907 \tTraining Accuracy: 67.207071656949 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 288 \tLoss: 0.703295290470 \tTraining Accuracy: 67.507993229265 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 289 \tLoss: 0.702527225018 \tTraining Accuracy: 67.455331954109 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 290 \tLoss: 0.701513111591 \tTraining Accuracy: 68.000752303931 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 291 \tLoss: 0.700887501240 \tTraining Accuracy: 67.911729672121 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 292 \tLoss: 0.700502514839 \tTraining Accuracy: 67.282302050028 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 293 \tLoss: 0.699809014797 \tTraining Accuracy: 67.822707040311 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 294 \tLoss: 0.699418246746 \tTraining Accuracy: 67.995736944392 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 295 \tLoss: 0.698832452297 \tTraining Accuracy: 67.751238166886 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 296 \tLoss: 0.698241293430 \tTraining Accuracy: 67.911729672121 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 297 \tLoss: 0.697394967079 \tTraining Accuracy: 68.114851733434 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 298 \tLoss: 0.696615099907 \tTraining Accuracy: 67.502977869726 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 299 \tLoss: 0.696257174015 \tTraining Accuracy: 67.654692495768 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 300 \tLoss: 0.695881724358 \tTraining Accuracy: 67.761268885963 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 301 \tLoss: 0.695868670940 \tTraining Accuracy: 67.930537270391 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 302 \tLoss: 0.695698916912 \tTraining Accuracy: 67.312394207260 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 303 \tLoss: 0.695302665234 \tTraining Accuracy: 68.266566359476 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 304 \tLoss: 0.694786667824 \tTraining Accuracy: 67.489185630995 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 305 \tLoss: 0.693883836269 \tTraining Accuracy: 67.793868722964 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 306 \tLoss: 0.693734169006 \tTraining Accuracy: 67.825214720080 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 307 \tLoss: 0.694001138210 \tTraining Accuracy: 67.802645602157 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 308 \tLoss: 0.693976283073 \tTraining Accuracy: 67.628361858191 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 309 \tLoss: 0.693637013435 \tTraining Accuracy: 67.916745031659 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 310 \tLoss: 0.693061351776 \tTraining Accuracy: 67.429001316532 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 311 \tLoss: 0.692535996437 \tTraining Accuracy: 67.980690865776 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 312 \tLoss: 0.692209184170 \tTraining Accuracy: 67.593254341421 \t Validation Accuracy: 65.822784810127\n",
            "Epoch: 313 \tLoss: 0.691667437553 \tTraining Accuracy: 67.874114475581 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 314 \tLoss: 0.691166043282 \tTraining Accuracy: 67.849037677889 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 315 \tLoss: 0.690687596798 \tTraining Accuracy: 67.476647232148 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 316 \tLoss: 0.689945816994 \tTraining Accuracy: 67.839006958811 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 317 \tLoss: 0.689552485943 \tTraining Accuracy: 67.854053037427 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 318 \tLoss: 0.688881039619 \tTraining Accuracy: 68.103567174472 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 319 \tLoss: 0.688310503960 \tTraining Accuracy: 67.597015861075 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 320 \tLoss: 0.688500344753 \tTraining Accuracy: 67.630869537960 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 321 \tLoss: 0.687729835510 \tTraining Accuracy: 67.778822644348 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 322 \tLoss: 0.687228262424 \tTraining Accuracy: 67.704846091154 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 323 \tLoss: 0.686912298203 \tTraining Accuracy: 67.943075669237 \t Validation Accuracy: 65.822784810127\n",
            "Epoch: 324 \tLoss: 0.686771690845 \tTraining Accuracy: 67.709861450693 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 325 \tLoss: 0.685959815979 \tTraining Accuracy: 67.969406306815 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 326 \tLoss: 0.685328483582 \tTraining Accuracy: 68.030844461162 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 327 \tLoss: 0.684724092484 \tTraining Accuracy: 67.597015861075 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 328 \tLoss: 0.684049367905 \tTraining Accuracy: 67.907968152467 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 329 \tLoss: 0.683575153351 \tTraining Accuracy: 67.920506551313 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 330 \tLoss: 0.683054208755 \tTraining Accuracy: 67.860322236850 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 331 \tLoss: 0.682683348656 \tTraining Accuracy: 68.009529183123 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 332 \tLoss: 0.682580173016 \tTraining Accuracy: 67.644661776691 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 333 \tLoss: 0.682304203510 \tTraining Accuracy: 68.146197730550 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 334 \tLoss: 0.682460427284 \tTraining Accuracy: 67.485424111341 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 335 \tLoss: 0.682171165943 \tTraining Accuracy: 67.579462102689 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 336 \tLoss: 0.681895971298 \tTraining Accuracy: 68.157482289512 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 337 \tLoss: 0.681683778763 \tTraining Accuracy: 67.840260798696 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 338 \tLoss: 0.681395888329 \tTraining Accuracy: 67.976929346123 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 339 \tLoss: 0.680852234364 \tTraining Accuracy: 67.721146009655 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 340 \tLoss: 0.680106580257 \tTraining Accuracy: 67.911729672121 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 341 \tLoss: 0.679969072342 \tTraining Accuracy: 67.996990784277 \t Validation Accuracy: 55.696202531646\n",
            "Epoch: 342 \tLoss: 0.679708778858 \tTraining Accuracy: 68.449626982634 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 343 \tLoss: 0.679395735264 \tTraining Accuracy: 67.953106388314 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 344 \tLoss: 0.679379761219 \tTraining Accuracy: 67.727415209078 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 345 \tLoss: 0.679058015347 \tTraining Accuracy: 68.128643972165 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 346 \tLoss: 0.678869783878 \tTraining Accuracy: 67.743715127578 \t Validation Accuracy: 56.962025316456\n",
            "Epoch: 347 \tLoss: 0.678467273712 \tTraining Accuracy: 67.639646417153 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 348 \tLoss: 0.678177535534 \tTraining Accuracy: 67.859068396966 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 349 \tLoss: 0.677986264229 \tTraining Accuracy: 67.709861450693 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 350 \tLoss: 0.677780687809 \tTraining Accuracy: 68.054667418971 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 351 \tLoss: 0.677316606045 \tTraining Accuracy: 68.156228449627 \t Validation Accuracy: 55.696202531646\n",
            "Epoch: 352 \tLoss: 0.677242517471 \tTraining Accuracy: 67.381355400915 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 353 \tLoss: 0.676845967770 \tTraining Accuracy: 68.012036862893 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 354 \tLoss: 0.676524043083 \tTraining Accuracy: 67.919252711429 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 355 \tLoss: 0.676298856735 \tTraining Accuracy: 67.907968152467 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 356 \tLoss: 0.676206052303 \tTraining Accuracy: 68.034605980816 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 357 \tLoss: 0.675729393959 \tTraining Accuracy: 67.828976239734 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 358 \tLoss: 0.675363123417 \tTraining Accuracy: 68.055921258855 \t Validation Accuracy: 56.962025316456\n",
            "Epoch: 359 \tLoss: 0.674737632275 \tTraining Accuracy: 67.988213905084 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 360 \tLoss: 0.674564599991 \tTraining Accuracy: 67.727415209078 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 361 \tLoss: 0.674416184425 \tTraining Accuracy: 68.079744216664 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 362 \tLoss: 0.674146056175 \tTraining Accuracy: 68.122374772742 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 363 \tLoss: 0.674168467522 \tTraining Accuracy: 67.844022318350 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 364 \tLoss: 0.673678457737 \tTraining Accuracy: 68.252774120745 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 365 \tLoss: 0.673478186131 \tTraining Accuracy: 68.226443483167 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 366 \tLoss: 0.673432350159 \tTraining Accuracy: 68.074728857125 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 367 \tLoss: 0.673701405525 \tTraining Accuracy: 67.645915616576 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 368 \tLoss: 0.673675775528 \tTraining Accuracy: 66.997680396213 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 369 \tLoss: 0.673101782799 \tTraining Accuracy: 68.290389317284 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 370 \tLoss: 0.672581672668 \tTraining Accuracy: 68.388188828287 \t Validation Accuracy: 65.822784810127\n",
            "Epoch: 371 \tLoss: 0.672256410122 \tTraining Accuracy: 68.060936618394 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 372 \tLoss: 0.672073721886 \tTraining Accuracy: 67.980690865776 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 373 \tLoss: 0.672200262547 \tTraining Accuracy: 68.077236536894 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 374 \tLoss: 0.672028958797 \tTraining Accuracy: 67.906714312582 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 375 \tLoss: 0.671517610550 \tTraining Accuracy: 67.647169456460 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 376 \tLoss: 0.670921921730 \tTraining Accuracy: 67.986960065200 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 377 \tLoss: 0.670463025570 \tTraining Accuracy: 68.292896997053 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 378 \tLoss: 0.670657396317 \tTraining Accuracy: 67.813930161118 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 379 \tLoss: 0.670582175255 \tTraining Accuracy: 67.602031220613 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 380 \tLoss: 0.670127630234 \tTraining Accuracy: 68.276597078553 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 381 \tLoss: 0.670181095600 \tTraining Accuracy: 68.187574446743 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 382 \tLoss: 0.670256435871 \tTraining Accuracy: 68.027082941508 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 383 \tLoss: 0.670749664307 \tTraining Accuracy: 68.042129020124 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 384 \tLoss: 0.671154141426 \tTraining Accuracy: 67.923014231083 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 385 \tLoss: 0.671047449112 \tTraining Accuracy: 67.812676321234 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 386 \tLoss: 0.670544862747 \tTraining Accuracy: 68.138674691242 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 387 \tLoss: 0.670266926289 \tTraining Accuracy: 68.246504921322 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 388 \tLoss: 0.670406043530 \tTraining Accuracy: 68.070967337471 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 389 \tLoss: 0.670334219933 \tTraining Accuracy: 68.084759576202 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 390 \tLoss: 0.670338153839 \tTraining Accuracy: 67.831483919503 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 391 \tLoss: 0.670565128326 \tTraining Accuracy: 68.287881637515 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 392 \tLoss: 0.670834362507 \tTraining Accuracy: 68.057175098740 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 393 \tLoss: 0.670652747154 \tTraining Accuracy: 67.911729672121 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 394 \tLoss: 0.670296072960 \tTraining Accuracy: 67.499216350072 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 395 \tLoss: 0.670403957367 \tTraining Accuracy: 68.240235721898 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 396 \tLoss: 0.669945597649 \tTraining Accuracy: 67.970660146699 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 397 \tLoss: 0.670028805733 \tTraining Accuracy: 67.880383675005 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 398 \tLoss: 0.670182466507 \tTraining Accuracy: 68.068459657702 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 399 \tLoss: 0.669867694378 \tTraining Accuracy: 68.391950347941 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 400 \tLoss: 0.669916093349 \tTraining Accuracy: 67.578208262805 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 401 \tLoss: 0.669180810452 \tTraining Accuracy: 68.257789480283 \t Validation Accuracy: 65.822784810127\n",
            "Epoch: 402 \tLoss: 0.669351398945 \tTraining Accuracy: 67.941821829352 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 403 \tLoss: 0.669419944286 \tTraining Accuracy: 67.958121747853 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 404 \tLoss: 0.669607102871 \tTraining Accuracy: 68.098551814933 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 405 \tLoss: 0.669894933701 \tTraining Accuracy: 67.723653689424 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 406 \tLoss: 0.669830679893 \tTraining Accuracy: 68.083505736317 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 407 \tLoss: 0.669904053211 \tTraining Accuracy: 68.319227634631 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 408 \tLoss: 0.669968903065 \tTraining Accuracy: 68.319227634631 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 409 \tLoss: 0.670400857925 \tTraining Accuracy: 68.024575261739 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 410 \tLoss: 0.670851528645 \tTraining Accuracy: 68.187574446743 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 411 \tLoss: 0.670905828476 \tTraining Accuracy: 68.152466929973 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 412 \tLoss: 0.670426964760 \tTraining Accuracy: 67.890414394082 \t Validation Accuracy: 67.088607594937\n",
            "Epoch: 413 \tLoss: 0.670266449451 \tTraining Accuracy: 68.233966522475 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 414 \tLoss: 0.670467972755 \tTraining Accuracy: 67.376340041377 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 415 \tLoss: 0.670512616634 \tTraining Accuracy: 68.044636699893 \t Validation Accuracy: 67.088607594937\n",
            "Epoch: 416 \tLoss: 0.670345187187 \tTraining Accuracy: 68.351827471632 \t Validation Accuracy: 65.822784810127\n",
            "Epoch: 417 \tLoss: 0.670041203499 \tTraining Accuracy: 67.407686038493 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 418 \tLoss: 0.669733166695 \tTraining Accuracy: 68.181305247320 \t Validation Accuracy: 67.088607594937\n",
            "Epoch: 419 \tLoss: 0.669247984886 \tTraining Accuracy: 68.370635069902 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 420 \tLoss: 0.669189214706 \tTraining Accuracy: 68.157482289512 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 421 \tLoss: 0.668910741806 \tTraining Accuracy: 67.546862265689 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 422 \tLoss: 0.668802618980 \tTraining Accuracy: 68.213905084321 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 423 \tLoss: 0.668554604053 \tTraining Accuracy: 68.630179926023 \t Validation Accuracy: 65.822784810127\n",
            "Epoch: 424 \tLoss: 0.668726325035 \tTraining Accuracy: 67.808914801580 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 425 \tLoss: 0.668588995934 \tTraining Accuracy: 67.786345683656 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 426 \tLoss: 0.668592929840 \tTraining Accuracy: 68.437088583788 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 427 \tLoss: 0.667915225029 \tTraining Accuracy: 67.539339226381 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 428 \tLoss: 0.668030381203 \tTraining Accuracy: 68.353081311517 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 429 \tLoss: 0.667930424213 \tTraining Accuracy: 68.297912356592 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 430 \tLoss: 0.667849063873 \tTraining Accuracy: 68.543664973983 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 431 \tLoss: 0.668027579784 \tTraining Accuracy: 67.833991599273 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 432 \tLoss: 0.667634606361 \tTraining Accuracy: 67.141871982948 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 433 \tLoss: 0.667498171329 \tTraining Accuracy: 68.566234091906 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 434 \tLoss: 0.668048799038 \tTraining Accuracy: 68.251520280860 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 435 \tLoss: 0.668219625950 \tTraining Accuracy: 67.757507366309 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 436 \tLoss: 0.667893290520 \tTraining Accuracy: 67.854053037427 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 437 \tLoss: 0.668056488037 \tTraining Accuracy: 67.944329509122 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 438 \tLoss: 0.668348670006 \tTraining Accuracy: 68.532380415021 \t Validation Accuracy: 56.962025316456\n",
            "Epoch: 439 \tLoss: 0.668057918549 \tTraining Accuracy: 67.253463732681 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 440 \tLoss: 0.668342709541 \tTraining Accuracy: 68.576264810984 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 441 \tLoss: 0.667844295502 \tTraining Accuracy: 68.400727227133 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 442 \tLoss: 0.668252885342 \tTraining Accuracy: 68.106074854241 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 443 \tLoss: 0.668172657490 \tTraining Accuracy: 68.449626982634 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 444 \tLoss: 0.668062508106 \tTraining Accuracy: 68.267820199361 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 445 \tLoss: 0.668571293354 \tTraining Accuracy: 67.753745846655 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 446 \tLoss: 0.668539166451 \tTraining Accuracy: 68.330512193593 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 447 \tLoss: 0.668089210987 \tTraining Accuracy: 68.163751488935 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 448 \tLoss: 0.667546808720 \tTraining Accuracy: 68.682841201179 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 449 \tLoss: 0.667621970177 \tTraining Accuracy: 68.052159739201 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 450 \tLoss: 0.667346179485 \tTraining Accuracy: 68.213905084321 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 451 \tLoss: 0.666836440563 \tTraining Accuracy: 68.215158924205 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 452 \tLoss: 0.666332185268 \tTraining Accuracy: 67.993229264623 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 453 \tLoss: 0.666531801224 \tTraining Accuracy: 68.087267255971 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 454 \tLoss: 0.666264533997 \tTraining Accuracy: 68.292896997053 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 455 \tLoss: 0.666137456894 \tTraining Accuracy: 68.363112030594 \t Validation Accuracy: 58.227848101266\n",
            "Epoch: 456 \tLoss: 0.666075527668 \tTraining Accuracy: 68.000752303931 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 457 \tLoss: 0.665858447552 \tTraining Accuracy: 67.867845276158 \t Validation Accuracy: 65.822784810127\n",
            "Epoch: 458 \tLoss: 0.665651261806 \tTraining Accuracy: 68.532380415021 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 459 \tLoss: 0.665709853172 \tTraining Accuracy: 68.195097486051 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 460 \tLoss: 0.666147649288 \tTraining Accuracy: 68.225189643283 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 461 \tLoss: 0.666024684906 \tTraining Accuracy: 68.153720769858 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 462 \tLoss: 0.665359020233 \tTraining Accuracy: 68.073475017240 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 463 \tLoss: 0.665228247643 \tTraining Accuracy: 67.959375587737 \t Validation Accuracy: 69.620253164557\n",
            "Epoch: 464 \tLoss: 0.665040314198 \tTraining Accuracy: 68.289135477400 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 465 \tLoss: 0.664925456047 \tTraining Accuracy: 68.093536455395 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 466 \tLoss: 0.664741992950 \tTraining Accuracy: 68.414519465864 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 467 \tLoss: 0.664435803890 \tTraining Accuracy: 68.078490376779 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 468 \tLoss: 0.663978874683 \tTraining Accuracy: 67.944329509122 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 469 \tLoss: 0.663413584232 \tTraining Accuracy: 68.391950347941 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 470 \tLoss: 0.663357317448 \tTraining Accuracy: 68.596326249138 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 471 \tLoss: 0.663534581661 \tTraining Accuracy: 67.806407121811 \t Validation Accuracy: 64.556962025316\n",
            "Epoch: 472 \tLoss: 0.663239657879 \tTraining Accuracy: 68.154974609742 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 473 \tLoss: 0.662917613983 \tTraining Accuracy: 68.333019873362 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 474 \tLoss: 0.663187861443 \tTraining Accuracy: 68.483480659520 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 475 \tLoss: 0.663435816765 \tTraining Accuracy: 68.385681148517 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 476 \tLoss: 0.662995815277 \tTraining Accuracy: 68.127390132280 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 477 \tLoss: 0.662423670292 \tTraining Accuracy: 68.087267255971 \t Validation Accuracy: 65.822784810127\n",
            "Epoch: 478 \tLoss: 0.662189960480 \tTraining Accuracy: 68.674064321986 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 479 \tLoss: 0.661524832249 \tTraining Accuracy: 68.162497649050 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 480 \tLoss: 0.661345303059 \tTraining Accuracy: 67.612061939690 \t Validation Accuracy: 65.822784810127\n",
            "Epoch: 481 \tLoss: 0.660928547382 \tTraining Accuracy: 68.470942260673 \t Validation Accuracy: 65.822784810127\n",
            "Epoch: 482 \tLoss: 0.660953581333 \tTraining Accuracy: 68.304181556015 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 483 \tLoss: 0.660865783691 \tTraining Accuracy: 68.333019873362 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 484 \tLoss: 0.660179913044 \tTraining Accuracy: 68.227697323052 \t Validation Accuracy: 65.822784810127\n",
            "Epoch: 485 \tLoss: 0.660064578056 \tTraining Accuracy: 67.871606795812 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 486 \tLoss: 0.659611880779 \tTraining Accuracy: 68.344304432324 \t Validation Accuracy: 65.822784810127\n",
            "Epoch: 487 \tLoss: 0.659630477428 \tTraining Accuracy: 67.897937433390 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 488 \tLoss: 0.658985674381 \tTraining Accuracy: 68.652749043947 \t Validation Accuracy: 59.493670886076\n",
            "Epoch: 489 \tLoss: 0.658330142498 \tTraining Accuracy: 68.129897812049 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 490 \tLoss: 0.658245265484 \tTraining Accuracy: 67.999498464046 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 491 \tLoss: 0.658877730370 \tTraining Accuracy: 68.094790295279 \t Validation Accuracy: 56.962025316456\n",
            "Epoch: 492 \tLoss: 0.658834040165 \tTraining Accuracy: 68.341796752555 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 493 \tLoss: 0.658816516399 \tTraining Accuracy: 68.065951977932 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 494 \tLoss: 0.658917427063 \tTraining Accuracy: 68.371888909786 \t Validation Accuracy: 67.088607594937\n",
            "Epoch: 495 \tLoss: 0.658582806587 \tTraining Accuracy: 68.038367500470 \t Validation Accuracy: 63.291139240506\n",
            "Epoch: 496 \tLoss: 0.658167362213 \tTraining Accuracy: 68.123628612626 \t Validation Accuracy: 60.759493670886\n",
            "Epoch: 497 \tLoss: 0.657977044582 \tTraining Accuracy: 67.608300420036 \t Validation Accuracy: 62.025316455696\n",
            "Epoch: 498 \tLoss: 0.657836735249 \tTraining Accuracy: 68.532380415021 \t Validation Accuracy: 65.822784810127\n",
            "Epoch: 499 \tLoss: 0.657395541668 \tTraining Accuracy: 68.835809667106 \t Validation Accuracy: 64.556962025316\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "zHVG-7NmMVus",
        "outputId": "b560b273-59d7-4e11-daaa-e428c283fdf2"
      },
      "source": [
        "# plot the training dynamcis\n",
        "plot(loss, train_socre, valid_score)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YC2ce3e_P6XE"
      },
      "source": [
        "# generate some text given the model and an initial chatacter, vocab_size, and the text length\n",
        "def generate_text(model, init, d, seq_length):\n",
        "  char = init\n",
        "  idx = char_to_ix[char]\n",
        "  h = torch.zeros(d)\n",
        "  txt = []\n",
        "  txt.append(char)\n",
        "  with torch.no_grad():\n",
        "    for _ in range(seq_length):\n",
        "      inp = onehot(idx, d)\n",
        "      # print(inp)\n",
        "      y, h = model(torch.unsqueeze(inp, dim=0).to(device), h.to(device))\n",
        "      probs = F.softmax(y, dim=1).cpu().numpy()[0]\n",
        "      idx =  np.random.choice(d, 1, p=probs)[0] # sample from the output disrbution\n",
        "      txt.append(ix_to_char[idx])\n",
        "  return \"\".join(txt)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "wB0TQ101fMne",
        "outputId": "70c4b844-92d6-4ed3-8f13-af8c129de26a"
      },
      "source": [
        "\"\".join(txt)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ThAs byithey dibleder hoges that arally have of the brain, the exply that she gruncings; of the intere protwjee, is as the solidide in a werld, achion an un the brain gious the relucad pretantstince causal byothem.\\nNow, tous pretantes. Nowevion for how the burally in these liveln with le\\nthat notrence\\nstath for a micro-sysiatilick all in ortich hecouratk is to a\\npoinge nerd in paislar ammoust is to\\nde bean brtwatitus eft that is compotst lifectlaine it they arfic of the that bray that have a cer'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWBT-sBrccT4"
      },
      "source": [
        ""
      ],
      "execution_count": 458,
      "outputs": []
    }
  ]
}